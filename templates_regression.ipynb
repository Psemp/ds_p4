{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "from dotenv import load_dotenv\n",
    "from sklearn import preprocessing, model_selection, linear_model\n",
    "from sklearn import metrics, dummy\n",
    "\n",
    "from scripts.models.regressions import Regressions\n",
    "\n",
    "load_dotenv()\n",
    "sns.color_palette('colorblind')\n",
    "plt.style.use('Solarize_Light2')\n",
    "\n",
    "# Setting default DPI, pulling it from dotenv if it exists, setting it on 100 if not\n",
    "\n",
    "try:\n",
    "    pc_cores = int(os.getenv('CORES'))\n",
    "\n",
    "except TypeError:\n",
    "    pc_cores = 4\n",
    "\n",
    "try:\n",
    "    pc_dpi = int(os.getenv('DPI'))\n",
    "\n",
    "except TypeError:\n",
    "    pc_dpi = 100\n",
    "\n",
    "if pc_dpi is None:\n",
    "    pc_dpi = 100\n",
    "\n",
    "if pc_dpi >= 155:\n",
    "    pc_dpi = 155\n",
    "\n",
    "## NOTES : cv = RepeatedKFold(n_splits=10, n_repeats=3, random_state=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_ghg_eui = \"./data/seattle_predict_ghg_eui.csv\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_model = pd.read_csv(file_ghg_eui).astype(float)\n",
    "\n",
    "df_model.columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_model.set_index(\"OSEBuildingID\", inplace=True)\n",
    "df_model.dropna(inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Target_1 : target_GHGEmissionsIntensity(kgCO2e/ft2) : two cols\n",
    "\n",
    "droplist_1 = [\n",
    "    \"scaled_GHGEmissionsIntensity(kgCO2e/ft2)\",  # Scaled target\n",
    "    \"target_SourceEUI(kWh/m2)\"  # not to scale\n",
    "    ]\n",
    "\n",
    "df_model_ghg = df_model.drop(columns=droplist_1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ghg_target = \"target_GHGEmissionsIntensity(kgCO2e/ft2)\"\n",
    "ghg_regression = Regressions(dataframe=df_model_ghg, target_col=ghg_target)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha_range = np.arange(20, 70, 0.05)\n",
    "\n",
    "ridge_cv_l_one_out = linear_model.RidgeCV(\n",
    "    fit_intercept=False,\n",
    "    alphas=alpha_range,\n",
    "    store_cv_values=True\n",
    "    )\n",
    "\n",
    "ridge_cv_l_one_out.fit(ghg_regression.X_train, ghg_regression.y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mses_ridge = np.mean(ridge_cv_l_one_out.cv_values_, axis=0)[0]\n",
    "rmses_ridge = np.sqrt(mses_ridge)\n",
    "predict_train = ridge_cv_l_one_out.predict(X=ghg_regression.X_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1) = plt.subplots(\n",
    "    ncols=1,\n",
    "    nrows=1,\n",
    "    figsize=(4, 4),\n",
    "    dpi=pc_dpi,\n",
    ")\n",
    "\n",
    "ax1.plot(alpha_range, np.sqrt(mses_ridge))\n",
    "\n",
    "###\n",
    "# Titles/Lables\n",
    "\n",
    "#\n",
    "###\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(ridge_cv_l_one_out.alpha_)\n",
    "np.sqrt(abs(ridge_cv_l_one_out.best_score_))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha_range = np.arange(50, 120, 0.05)\n",
    "\n",
    "kfolds = model_selection.RepeatedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "\n",
    "ridge_cv_kfolds = linear_model.RidgeCV(\n",
    "    fit_intercept=False,\n",
    "    alphas=alpha_range,\n",
    "    cv=kfolds\n",
    "    )\n",
    "\n",
    "ridge_cv_kfolds.fit(ghg_regression.X_train, ghg_regression.y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.sqrt(ridge_cv_kfolds.best_score_))\n",
    "print(ridge_cv_kfolds.alpha_)\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.dummy import DummyRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dum_dum_reg = DummyRegressor()\n",
    "clf_dum_dum = cross_val_score(\n",
    "    estimator=dum_dum_reg,\n",
    "    X=ghg_regression.X_train,\n",
    "    y=ghg_regression.y_train,\n",
    "    scoring=\"neg_mean_squared_error\",\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "dum_dum_reg.fit(X=ghg_regression.X_train, y=ghg_regression.y_train)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On ne peut verifier la qualit√© de la regression que s'il on peut evaluer les differentes valeurs de lambda en fonction de la validation croisee. La seule validation croisee precise permettant cela est la validation Leave One Out (defaut)\n",
    "\n",
    "Construction d'une classe permettant d'ajuster ces parametres au besoin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.linear_model import LinearRegression, RidgeCV, LassoCV, ElasticNetCV\n",
    "from sklearn.model_selection import train_test_split, cross_validate\n",
    "from sklearn.dummy import DummyRegressor\n",
    "from sklearn import metrics\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "\n",
    "class Linear_reg():\n",
    "\n",
    "    common_parameters = {\n",
    "        \"scoring\": \"neg_mean_squared_error\",\n",
    "        \"cv\": None,  # Default = Leave One Out\n",
    "        \"n_jobs\": -1  # Use all cores\n",
    "    }\n",
    "\n",
    "    def __init__(self, dataframe: pd.DataFrame, target: str, override_common: dict = None, split: float = None):\n",
    "        self.df_origin = dataframe\n",
    "\n",
    "        ##\n",
    "        # Train test split\n",
    "        self.df_train, self.df_test = train_test_split(self.df_origin, test_size=split)\n",
    "        self.X_train = self.df_train.drop(columns=target).to_numpy()\n",
    "        self.X_test = self.df_test.drop(columns=target).to_numpy()\n",
    "\n",
    "        self.y_train = self.df_train[[target]].to_numpy()\n",
    "        self.y_test = self.df_test[[target]].to_numpy()\n",
    "        #\n",
    "        ##\n",
    "\n",
    "        self.std_calc, self.ridge_calc, self.lasso_calc, self.enet_calc = False, False, False, False\n",
    "        self.listed_ytrain = [value[0] for value in self.y_train]\n",
    "        self.listed_ytest = [value[0] for value in self.y_test]\n",
    "        self.df_predictions = pd.DataFrame({\"True\": self.listed_ytest})\n",
    "\n",
    "        # Dummy\n",
    "        dummy_reg = DummyRegressor()\n",
    "        scores_dummy = cross_validate(\n",
    "            estimator=dummy_reg,\n",
    "            X=self.X_train,\n",
    "            y=self.y_train,\n",
    "            scoring=[\"neg_mean_squared_error\", \"r2\"],\n",
    "            n_jobs=-1,\n",
    "        )\n",
    "\n",
    "        dummy_reg.fit(X=self.X_train, y=self.y_train)\n",
    "\n",
    "        y_pred_dummy = dummy_reg.predict(self.X_test)\n",
    "        dummy_reg.fit(\n",
    "                X=self.X_train,\n",
    "                y=self.y_train\n",
    "            )\n",
    "\n",
    "        # Metrics Train\n",
    "        dummy_mean_mse_train = scores_dummy[\"test_neg_mean_squared_error\"].mean()\n",
    "        rmse_dummy_train = np.sqrt(abs(dummy_mean_mse_train))\n",
    "        r2_dummy_train = scores_dummy[\"test_r2\"].mean()\n",
    "        # /Metrics Train\n",
    "\n",
    "        # Metrics Test\n",
    "        dummy_mse_test = metrics.mean_squared_error(y_pred=y_pred_dummy, y_true=self.y_test)\n",
    "        dummy_rmse_test = np.sqrt(abs(dummy_mse_test))\n",
    "        std_r2_test = metrics.r2_score(y_pred=y_pred_dummy, y_true=self.y_test)\n",
    "        self.table_dummy = Linear_reg.get_table(\n",
    "            scores_train=(rmse_dummy_train, r2_dummy_train),\n",
    "            scores_test=(dummy_rmse_test, std_r2_test)\n",
    "            )\n",
    "        # /Dummy\n",
    "\n",
    "    def get_table(scores_train, scores_test):\n",
    "        # Tuple shape : [0] = RMSE, [1] = R2\n",
    "        return pd.DataFrame(\n",
    "            columns=[\"RMSE\", \"R2\"],\n",
    "            data=[[scores_train[0], scores_test[0]], [scores_train[1], scores_test[1]]],\n",
    "            index=[\"Train\", \"Test\"]\n",
    "        )\n",
    "\n",
    "    def get_plot(rmse_list, alpha_list):\n",
    "        ax = plt.plot(alpha_list, rmse_list)\n",
    "        return ax\n",
    "\n",
    "    def standard_regression(self):\n",
    "\n",
    "        self.lin_reg = LinearRegression(fit_intercept=False)\n",
    "\n",
    "        scores_regression = cross_validate(\n",
    "                    self.lin_reg,\n",
    "                    X=self.X_train,\n",
    "                    y=self.y_train,\n",
    "                    scoring=[\"neg_mean_squared_error\", \"r2\"],\n",
    "                    cv=Linear_reg.common_parameters[\"cv\"],\n",
    "                    n_jobs=Linear_reg.common_parameters[\"n_jobs\"],\n",
    "                )\n",
    "        self.lin_reg.fit(\n",
    "            X=self.X_train,\n",
    "            y=self.y_train\n",
    "        )\n",
    "        # Metrics Train\n",
    "        std_reg_mean_mse_train = scores_regression[\"test_neg_mean_squared_error\"].mean()\n",
    "        std_mean_rmse_train = np.sqrt(abs(std_reg_mean_mse_train))\n",
    "        std_mean_r2_train = scores_regression[\"test_r2\"].mean()\n",
    "        # /Metrics Train\n",
    "        y_pred_basic = self.lin_reg.predict(self.X_test)\n",
    "        # Metrics Test\n",
    "        std_mse_test = metrics.mean_squared_error(y_pred=y_pred_basic, y_true=self.y_test)\n",
    "        std_rmse_test = np.sqrt(abs(std_mse_test))\n",
    "        std_r2_test = metrics.r2_score(y_pred=y_pred_basic, y_true=self.y_test)\n",
    "        # /Metrics Test\n",
    "        self.std_table = Linear_reg.get_table(\n",
    "            scores_train=(std_mean_rmse_train, std_mean_r2_train),\n",
    "            scores_test=(std_rmse_test, std_r2_test)\n",
    "        )\n",
    "        self.df_predictions[\"basic_regression\"] = y_pred_basic\n",
    "        self.std_calc = True\n",
    "\n",
    "    def ridge_cv_oneout(self, alphas):\n",
    "        \"\"\"\n",
    "        Used to cross validate and find best hyperparameters\n",
    "        for ridge and lasso !only!, elasticNet is too different\n",
    "        to be generalized\n",
    "        \"\"\"\n",
    "        self.ridge_cv = RidgeCV(\n",
    "            fit_intercept=False,\n",
    "            alphas=alphas,\n",
    "            store_cv_values=True,\n",
    "        )\n",
    "\n",
    "        self.ridge_cv.fit(\n",
    "            X=self.X_train,\n",
    "            y=self.y_train\n",
    "        )\n",
    "\n",
    "        self.ridge_best_alpha = self.ridge_cv.alpha_\n",
    "\n",
    "        # Metrics Train\n",
    "        predict_train = self.ridge_cv.predict(X=self.X_train)\n",
    "        mses_ridge = np.mean(self.ridge_cv.cv_values_, axis=0)[0]\n",
    "        rmses_ridge = np.sqrt(abs(mses_ridge))\n",
    "        rmse_train = np.sqrt(abs(self.ridge_cv.best_score_))\n",
    "        r2_train = metrics.r2_score(y_pred=predict_train, y_true=self.y_train)\n",
    "        # /Metrics Train\n",
    "\n",
    "        y_predict = self.ridge_cv.predict(X=self.X_test)\n",
    "\n",
    "        # Metrics Test\n",
    "        mse_test = metrics.mean_squared_error(y_pred=y_predict, y_true=self.y_test)\n",
    "        rmse_test = np.sqrt(abs(mse_test))\n",
    "        r2_test = metrics.r2_score(y_pred=y_predict, y_true=self.y_test)\n",
    "        # /Metrics Test\n",
    "\n",
    "        self.ridge_table = Linear_reg.get_table(\n",
    "            scores_train=(rmse_train, r2_train),\n",
    "            scores_test=(rmse_test, r2_test)\n",
    "        )\n",
    "        self.ridge_ax = Linear_reg.get_plot(rmse_list=rmses_ridge, alpha_list=self.ridge_cv.alphas)\n",
    "        self.df_predictions[\"Ridge\"] = y_predict\n",
    "\n",
    "    def lasso_cv_oneout(self, alphas, cv_method=10):\n",
    "        self.lasso_cv = LassoCV(\n",
    "            fit_intercept=False,\n",
    "            alphas=alphas,\n",
    "            cv=cv_method,\n",
    "            n_jobs=Linear_reg.common_parameters[\"n_jobs\"]\n",
    "        )\n",
    "        self.lasso_cv.fit(\n",
    "                X=self.X_train,\n",
    "                y=self.listed_ytrain\n",
    "            )\n",
    "        \n",
    "        self.lasso_best_alpha = self.lasso_cv.alpha_\n",
    "\n",
    "        # Metrics Train\n",
    "        predict_train = self.lasso_cv.predict(X=self.X_train)\n",
    "        mses = self.lasso_cv.mse_path_\n",
    "        mse_avg = []\n",
    "\n",
    "        for mse_list in mses:\n",
    "            mse_avg.append(np.mean(mse_list))\n",
    "\n",
    "        rmses_lasso = np.sqrt(mse_avg)\n",
    "        rmse_train = np.min(rmses_lasso)\n",
    "        r2_train = metrics.r2_score(y_pred=predict_train, y_true=self.listed_ytrain)\n",
    "        # /Metrics Train\n",
    "\n",
    "        y_predict = self.lasso_cv.predict(X=self.X_test)\n",
    "\n",
    "        # Metrics Test\n",
    "        mse_test = metrics.mean_squared_error(y_pred=y_predict, y_true=self.y_test)\n",
    "        rmse_test = np.sqrt(abs(mse_test))\n",
    "        r2_test = metrics.r2_score(y_pred=y_predict, y_true=self.y_test)\n",
    "        # /Metrics Test\n",
    "\n",
    "        self.lasso_table = Linear_reg.get_table(\n",
    "            scores_train=(rmse_train, r2_train),\n",
    "            scores_test=(rmse_test, r2_test)\n",
    "        )\n",
    "        self.lasso_ax = Linear_reg.get_plot(rmse_list=mse_avg, alpha_list=self.lasso_cv.alphas_)\n",
    "        self.df_predictions[\"Lasso\"] = y_predict\n",
    "\n",
    "    def elastic_net_cv_oneout(self, override_default: dict = None):\n",
    "\n",
    "        enet_parameters = Linear_reg.common_parameters\n",
    "        print(\"Step : Elastic Net\")\n",
    "        l1_range = np.arange(0.01, 0.99, 0.05)\n",
    "        self.elnet_cv = ElasticNetCV(\n",
    "            l1_ratio=l1_range,\n",
    "            n_alphas=150,\n",
    "            n_jobs=enet_parameters[\"n_jobs\"],\n",
    "            fit_intercept=False,\n",
    "\n",
    "        )\n",
    "\n",
    "        self.elnet_cv.fit(\n",
    "            X=self.X_train,\n",
    "            y=self.listed_ytrain\n",
    "        )\n",
    "\n",
    "        self.enet_best_l1_ratio = self.elnet_cv.l1_ratio_\n",
    "        self.enet_best_alpha = self.elnet_cv.alpha_\n",
    "        mses_elnet = self.elnet_cv.mse_path_\n",
    "        y_pred_enet = self.elnet_cv.predict(self.X_test)\n",
    "        # Metrics Train\n",
    "        predict_train = self.elnet_cv.predict(X=self.X_train)\n",
    "        mses = self.elnet_cv.mse_path_\n",
    "        mse_avg = []\n",
    "\n",
    "        for mse_list in mses:\n",
    "            mse_avg.append(np.mean(mse_list))\n",
    "\n",
    "        rmses_elnet = np.sqrt(mse_avg)\n",
    "        rmse_train = np.min(rmses_elnet)\n",
    "        r2_train = metrics.r2_score(y_pred=predict_train, y_true=self.listed_ytrain)\n",
    "        # /Metrics Train\n",
    "\n",
    "        y_predict = self.elnet_cv.predict(X=self.X_test)\n",
    "\n",
    "        # Metrics Test\n",
    "        mse_test = metrics.mean_squared_error(y_pred=y_predict, y_true=self.y_test)\n",
    "        rmse_test = np.sqrt(abs(mse_test))\n",
    "        r2_test = metrics.r2_score(y_pred=y_predict, y_true=self.y_test)\n",
    "        # /Metrics Test\n",
    "\n",
    "        self.elnet_table = Linear_reg.get_table(\n",
    "            scores_train=(rmse_train, r2_train),\n",
    "            scores_test=(rmse_test, r2_test)\n",
    "        )\n",
    "\n",
    "        self.df_predictions[\"Elastic_Net\"] = y_pred_enet\n",
    "\n",
    "        self.enet_calc = True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy_reg = DummyRegressor()\n",
    "scores_dummy = model_selection.cross_validate(\n",
    "    estimator=dummy_reg,\n",
    "    X=ghg_regression.X_train,\n",
    "    y=ghg_regression.y_train,\n",
    "    n_jobs=-1,\n",
    "    scoring=[\"neg_mean_squared_error\", \"r2\"]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# metrics.mean_squared_error(y_true=ghg_regression.y_train, y_pred=scores_dummy)\n",
    "# np.sqrt(abs(scores_dummy.mean()))\n",
    "scores_dummy.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_train = ridge_cv_l_one_out.predict(X=ghg_regression.X_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics.r2_score(y_pred=predict_train, y_true=ghg_regression.y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ridge_cv_l_one_out.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha_range = np.arange(0.2, 50, 0.05)\n",
    "\n",
    "def getax():\n",
    "    ax = plt.plot(alpha_range, np.sqrt(mses_ridge))\n",
    "    return ax\n",
    "\n",
    "###\n",
    "# Titles/Lables\n",
    "\n",
    "#\n",
    "###\n",
    "# plt.tight_layout()\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ghg_new_reg = Linear_reg(dataframe=df_model_ghg, target=ghg_target)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha_range = np.arange(1, 20, 0.05)\n",
    "\n",
    "ghg_new_reg.ridge_cv_oneout(alphas=alpha_range)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# alpha_lasso =np.arange(0.01, 15, 0.05)\n",
    "alpha_range = np.arange(0.1, 25, 0.05)\n",
    "\n",
    "ghg_new_reg.lasso_cv_oneout(alphas=alpha_range)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ghg_new_reg.elastic_net_cv_oneout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ghg_new_reg.ridge_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ghg_new_reg.lasso_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ghg_new_reg.standard_regression()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ghg_new_reg.std_table\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ghg_new_reg.elnet_table\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "1274e91d4c49da8d2c5027ac796fe23c6eef02ed77c0608f3ea1b98e1edcbe8a"
  },
  "kernelspec": {
   "display_name": "Python 3.10.4 ('env': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
