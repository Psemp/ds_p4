{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "from scripts.merge import merge_cols, complete_df\n",
    "from scripts.convert import convert_to_holy_metric, find_unit\n",
    "\n",
    "load_dotenv()\n",
    "plt.style.use('Solarize_Light2')\n",
    "\n",
    "# Setting default DPI, pulling it from dotenv if it exists, setting it on 100 if not\n",
    "\n",
    "pc_dpi = os.getenv('DPI')\n",
    "\n",
    "if pc_dpi is None:\n",
    "    pc_dpi = 100\n",
    "if pc_dpi is not None:\n",
    "    pc_dpi = int(pc_dpi)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <u>Pre Cleaning : </u>\n",
    "\n",
    "<u>Objectifs :</n>\n",
    "\n",
    "1. Formatter les données\n",
    "2. Identifier et retenir les variables indispensables à l'analyse et la construction de modeles predictifs\n",
    "3. Convertir les données au format metrique/internationnal (base 10)\n",
    "4. Exporter un dataset pret pour une analyse exploratoire"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <u> 1. Formattage des données </u>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Files\n",
    "\n",
    "twenty_fifteen_bm = \"data/2015-building-energy-benchmarking.csv\"\n",
    "twenty_sixteen_bm = \"data/2016-building-energy-benchmarking.csv\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fifteen = pd.read_csv(twenty_fifteen_bm, dtype=\"unicode\", low_memory=False)\n",
    "df_sixteen = pd.read_csv(twenty_sixteen_bm, dtype=\"unicode\", low_memory=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"info : \", df_fifteen.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"info : \", df_sixteen.info())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "id_fifteen_list = list(df_fifteen[\"OSEBuildingID\"])\n",
    "id_sixteen_list = list(df_sixteen[\"OSEBuildingID\"])\n",
    "\n",
    "only_in_fifteen = [ident for ident in id_fifteen_list if ident not in id_sixteen_list]\n",
    "only_in_sixteen = [ident for ident in id_sixteen_list if ident not in id_fifteen_list]\n",
    "\n",
    "print(\n",
    "    f\"\"\"{len(only_in_fifteen)} batiments ne sont présents que dans le benchmark 2015,\\\n",
    " et {len(only_in_sixteen)} batiments ne sont présents que dans le benchmark 2016 \"\"\"\n",
    "  )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_onl_fifteen = [col for col in df_fifteen.columns if col not in df_sixteen.columns]\n",
    "\n",
    "col_onl_sixteen = [col for col in df_sixteen.columns if col not in df_fifteen.columns]\n",
    "\n",
    "print(\"Nombre de variables non communes aux deux datasets : \", len(col_onl_fifteen) + len(col_onl_sixteen))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(col_onl_sixteen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(col_onl_fifteen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fifteen[\"Location\"].describe().top\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Observations :\n",
    "- Les deux datasets mentionnent la presence d'outliers, mais les metadonnees n'informent pas ce qui les determinent. Suppression des outliers.\n",
    "- Les données de localisation de l'annee 2015 sont presentes au format d'un dictionnaire, format plus efficace que les nombreuses variables de 2016. On pourra compresser les donnees de 2016 pour obtenir ce format\n",
    "- Certaines colonnes ne sont presentes que dans le dataset 2015, ces variables seront supprimées (droplist), d'autres ont un nom different et seront renommées\n",
    "- Certaines colonnes sont inutiles a l'etude et a la construction d'un modele mais apportent des informations interessantes sur les batiments si le besoin est. --> Creation d'un dataset Meta\n",
    "- L'etude specifie l'exclusion des batiments residentiels : identification et suppression\n",
    "- Plusieurs batiments ne sont pas communs aux deux datasets, on utilsera par defaut les informations les plus recentes (2016), et on importera les données manquantes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Outliers :\n",
    "\n",
    "df_sixteen = df_sixteen[df_sixteen[\"Outlier\"].isna()]\n",
    "df_fifteen = df_fifteen[df_fifteen[\"Outlier\"].isna()]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rename_sixteen = {\n",
    "    \"Comments\": \"Comment\",\n",
    "    \"TotalGHGEmissions\": \"GHGEmissions(MetricTonsCO2e)\",\n",
    "    \"GHGEmissionsIntensity\": \"GHGEmissionsIntensity(kgCO2e/ft2)\",\n",
    "    }\n",
    "\n",
    "droplist = [\n",
    "    \"Zip Codes\", \"Zipcode\", \"SPD Beats\", \"2010 Census Tracts\", \"City Council Districts\",\n",
    "    \"Seattle Police Department Micro Community Policing Plan Areas\", \"OtherFuelUse(kBtu)\",  # OtherFuelUse not present in both datasets\n",
    "    \"SPD Beats\", \"CouncilDistrictCode\", \"Outlier\", \"DataYear\", \"ZipCode\", \"NaturalGas(therms)\",  # Natural gas already present in another unit\n",
    "    ]\n",
    "\n",
    "# Columns not relevant to study but informative on the properties\n",
    "meta_df_cols = [\n",
    "    \"TaxParcelIdentificationNumber\", \"YearsENERGYSTARCertified\", \"Comment\", \"Location\", \"OSEBuildingID\",\n",
    "    \"PrimaryPropertyType\", \"PropertyName\", \"YearBuilt\"\n",
    "    ]\n",
    "\n",
    "meta_keep = [\"OSEBuildingID\", \"PrimaryPropertyType\", \"PropertyName\", \"YearBuilt\"]\n",
    "\n",
    "compress_cols = [\"Address\", \"City\", \"State\", \"Latitude\", \"Longitude\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fifteen = df_fifteen.drop(columns=droplist, errors=\"ignore\")\n",
    "df_sixteen = df_sixteen.drop(columns=droplist, errors=\"ignore\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using 2015 synthax, compression of compress cols & placing data in new col\n",
    "\n",
    "df_sixteen[\"Location\"] = np.nan\n",
    "\n",
    "merge_cols(origin_col_list=compress_cols, target_col_name=\"Location\", dataframe=df_sixteen)\n",
    "\n",
    "df_sixteen.drop(columns=compress_cols, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# renaming cols for merger\n",
    "\n",
    "df_sixteen.rename(columns=rename_sixteen, inplace=True)\n",
    "\n",
    "for col in df_sixteen.columns:\n",
    "    if col not in df_fifteen.columns:\n",
    "        raise BaseException(\"Mismatch\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merging : \n",
    "to_merge = df_fifteen[df_fifteen[\"OSEBuildingID\"].isin(only_in_fifteen)]\n",
    "\n",
    "df_seattle = pd.concat([df_sixteen, to_merge])\n",
    "\n",
    "if len(df_seattle[df_seattle.duplicated()]) > 0:\n",
    "    print(\"Duplicates, edit code ...\")\n",
    "else:\n",
    "    print(\"No duplicate, merger ok\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Created 2 meta dataframes and dropped the cols in main dfs\n",
    "\n",
    "meta_df_fifteen = df_fifteen[meta_df_cols]\n",
    "meta_df_sixteen = df_sixteen[meta_df_cols]\n",
    "\n",
    "meta_drop = [col for col in meta_df_cols if col not in meta_keep]\n",
    "\n",
    "df_fifteen.drop(columns=meta_drop, inplace=True)\n",
    "df_sixteen.drop(columns=meta_drop, inplace=True)\n",
    "df_seattle.drop(columns=meta_drop, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "btypes_fifteen = list(df_fifteen[\"BuildingType\"].unique())\n",
    "btypes_sixteen = list(df_sixteen[\"BuildingType\"].unique())\n",
    "\n",
    "btypes_both = btypes_fifteen\n",
    "[btypes_both.append(btype) for btype in btypes_sixteen if btype not in btypes_both]\n",
    "\n",
    "print(btypes_both)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Residential startswith multifamily\n",
    "\n",
    "residential = [btype for btype in btypes_both if str(btype).lower().startswith(\"multifamily\")]\n",
    "print(residential)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping residential\n",
    "\n",
    "df_seattle = df_seattle[~df_seattle[\"BuildingType\"].isin(residential)]\n",
    "\n",
    "# Check : \n",
    "\n",
    "btype_after_pass = list(df_seattle[\"BuildingType\"].unique())\n",
    "\n",
    "for btype in btype_after_pass:\n",
    "    if btype in residential:\n",
    "        print(\"Suppression Failed, advise\")\n",
    "        break\n",
    "    \n",
    "print(\"Suppression OK\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert\n",
    "\n",
    "unit_stop_chars = [\"(\", \")\", \"GFA\"]\n",
    "\n",
    "manual_ignore = [\"Electricity(kWh)\", \"GHGEmissions(MetricTonsCO2e)\", \"GHGEmissionsIntensity(kgCO2e/ft2)\"]\n",
    "\n",
    "unit_cols = [col for col in df_seattle.columns if (any(char in col for char in unit_stop_chars) and col not in manual_ignore)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unit_dict = dict.fromkeys(unit_cols)\n",
    "\n",
    "for col in unit_dict.keys(): \n",
    "    unit = find_unit(var_name=col, convert=True)[\"converted_unit\"]\n",
    "\n",
    "    if \"GFA\" in col:\n",
    "        new_name = col.replace(\"GFA\", \"Area(SquareMetre)\")\n",
    "    elif (\"(\"and \")\") in col:\n",
    "        start, end = col.find(\"(\"), col.find(\")\")\n",
    "        before = col[:start + 1]\n",
    "        after = col[end:]\n",
    "        new_name = f\"{before}{unit}{after}\"\n",
    "    \n",
    "    df_seattle[new_name] = np.nan\n",
    "    unit_dict[col] = new_name\n",
    "\n",
    "for key, value in unit_dict.items():\n",
    "\n",
    "    for index, series in df_seattle.iterrows():\n",
    "        df_seattle.at[index, value] = convert_to_holy_metric(data=series[key], var_name=key)\n",
    "\n",
    "df_seattle.drop(columns=unit_dict.keys(), inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_seattle.columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EPA has determined that source energy is the most equitable [...] cf. sources\n",
    "# |^| removing cols starting with site, except SiteEnergyUse(kWh) (no source)\n",
    "\n",
    "ignore_site = [\"SiteEnergyUse(kWh)\", \"SiteEnergyUseWN(kWh)\"]\n",
    "\n",
    "site_cols = [col for col in df_seattle.columns if (col.startswith(\"Site\") and col not in ignore_site)]\n",
    "df_seattle.drop(columns=site_cols, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Steam and Natural gas might be uncommon - Plotting ...\n",
    "\n",
    "fig, (ax1) = plt.subplots(\n",
    "    ncols=1,\n",
    "    nrows=1,\n",
    "    figsize=(22, 10),\n",
    "    dpi=pc_dpi,\n",
    ")\n",
    "\n",
    "ax1 = sns.boxplot(\n",
    "    data=df_seattle[[\"SteamUse(kWh)\", \"NaturalGas(kWh)\", \"SiteEnergyUse(kWh)\"]]\n",
    ")\n",
    "\n",
    "\n",
    "###\n",
    "# Titles/Lables\n",
    "\n",
    "ax1.set_ylim(0, 0.5 * 1e7)\n",
    "fig.suptitle(\"Representation de l'utilisation de la vapeur et du gaz naturel au sein du dataset\\\n",
    " ; visualistion de l'energie totale pour reference\")\n",
    "#\n",
    "###\n",
    "fig.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_seattle.drop(columns=[\"SteamUse(kWh)\"], inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_seattle.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "manual_drop = [\n",
    "    \"ListOfAllPropertyUseTypes\", \"SecondLargestPropertyUseType\",\n",
    "    \"ThirdLargestPropertyUseType\", \"DefaultData\", \"ComplianceStatus\",\n",
    "    \"SecondLargestPropertyUseTypeArea(SquareMetre)\", \"ThirdLargestPropertyUseTypeArea(SquareMetre)\",\n",
    "    ]\n",
    "\n",
    "df_seattle.drop(columns=manual_drop, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "0da0af6bf3f6033f1ed3bb9a018282c9b956ccf49d2ca4646969195110973d60"
  },
  "kernelspec": {
   "display_name": "Python 3.10.4 ('env': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
